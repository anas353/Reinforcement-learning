{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_q_learning_in_torch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnKrROVa8_SO"
      },
      "outputs": [],
      "source": [
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#s : stands for state\n",
        "#a : stands for action\n",
        "#r : stands for reward\n",
        "#thanks for Phil's help to make this project\n",
        "class DeepQLearning(nn.Module):\n",
        "    def __init__(self, ALPHA, input_dimension, fc1_dims, fc2_dims,\n",
        "                 number_of_as):\n",
        "        super(DeepQLearning, self).__init__()\n",
        "        self.input_dimension = input_dimension\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.number_of_as = number_of_as\n",
        "        self.function1 = nn.Linear(*self.input_dimension, self.function1)\n",
        "        self.function2 = nn.Linear(self.function1, self.function2)\n",
        "        self.function3 = nn.Linear(self.function2, self.number_of_as)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=ALPHA)\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cuda:1')\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, s):\n",
        "        s = T.Tensor(s).to(self.device)\n",
        "        x = F.relu(self.function1(s))\n",
        "        x = F.relu(self.function2(x))\n",
        "        as = self.function3(x)\n",
        "        return as\n",
        "\n",
        "class Agent(object):\n",
        "    def __init__(self, gamma, epsilon, alpha, input_dimension, batch_size, number_of_as,\n",
        "                 max_mem_size=100000, eps_end=0.01, eps_dec=0.996):\n",
        "        \n",
        "        \n",
        "        self.Q_function = DeepQLearning(alpha, number_of_as=self.number_of_as,\n",
        "                              input_dimension=input_dimension, function1=256, function2=256)\n",
        "        self.s_memory = np.zeros((self.mem_size, *input_dimension))\n",
        "        self.new_s_memory = np.zeros((self.mem_size, *input_dimension))\n",
        "        self.a_memory = np.zeros((self.mem_size, self.number_of_as),\n",
        "                                      dtype=np.uint8)\n",
        "        self.r_memory = np.zeros(self.mem_size)\n",
        "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.uint8)\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.EPS_MIN = eps_end\n",
        "        self.EPS_DEC = eps_dec\n",
        "        self.ALPHA = alpha\n",
        "        self.a_space = [i for i in range(number_of_as)]\n",
        "        self.number_of_as = number_of_as\n",
        "        self.mem_size = max_mem_size\n",
        "        self.batch_size = batch_size\n",
        "        self.mem_cntr = 0\n",
        "\n",
        "    def save_a_r_s(self, s, a, r, s_, terminal):\n",
        "        index = self.mem_cntr % self.mem_size\n",
        "        self.s_memory[index] = s\n",
        "        as = np.zeros(self.number_of_as)\n",
        "        as[a] = 1.0\n",
        "        self.a_memory[index] = as\n",
        "        self.r_memory[index] = r\n",
        "        self.new_s_memory[index] = s_\n",
        "        self.terminal_memory[index] = 1 - terminal\n",
        "        self.mem_cntr += 1\n",
        "\n",
        "    def take_an_action_action(self, s):\n",
        "        rand = np.random.random()\n",
        "        as = self.Q_function.forward(s)\n",
        "        if rand > self.epsilon:\n",
        "            a = T.argmax(as).item()\n",
        "        else:\n",
        "            a = np.random.choice(self.a_space)\n",
        "        return a\n",
        "\n",
        "    def learn(self):\n",
        "        if self.mem_cntr > self.batch_size:\n",
        "            self.Q_function.optimizer.zero_grad()\n",
        "\n",
        "            max_mem = self.mem_cntr if self.mem_cntr < self.mem_size \\\n",
        "                                    else self.mem_size\n",
        "\n",
        "            batch = np.random.choice(max_mem, self.batch_size)\n",
        "            s_batch = self.s_memory[batch]\n",
        "            a_batch = self.a_memory[batch]\n",
        "            val_a = np.array(self.a_space, dtype=np.int32)\n",
        "            ind_a = np.dot(a_batch, val_a)\n",
        "            r_batch = self.r_memory[batch]\n",
        "            new_s_batch = self.new_s_memory[batch]\n",
        "            terminal_batch = self.terminal_memory[batch]\n",
        "\n",
        "            r_batch = T.Tensor(r_batch).to(self.Q_function.device)\n",
        "            terminal_batch = T.Tensor(terminal_batch).to(self.Q_function.device)\n",
        "\n",
        "            Q_function = self.Q_function.forward(s_batch).to(self.Q_function.device)\n",
        "            q_target_function = Q_function.clone()\n",
        "            q_next = self.Q_function.forward(new_s_batch).to(self.Q_function.device)\n",
        "\n",
        "            batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
        "            q_target_function[batch_index, ind_a] = r_batch + \\\n",
        "                                self.gamma*T.max(q_next, dim=1)[0]*terminal_batch\n",
        "\n",
        "            self.epsilon = self.epsilon*self.EPS_DEC if self.epsilon > \\\n",
        "                           self.EPS_MIN else self.EPS_MIN\n",
        "\n",
        "            loss = self.Q_function.loss(q_target_function, Q_function).to(self.Q_function.device)\n",
        "            loss.backward()\n",
        "            self.Q_function.optimizer.step()"
      ],
      "metadata": {
        "id": "jtJ0iDlu-paU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MlETf7foZHpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}